# 💡Kafka 이중화로 다양한 장애 상황 완벽 대처하기

## 토스증권 Kafka 활용 현황

![Kafka 구조](./img/image.png)
- Kafka는 메시지를 발생시키는 **Producer**, 메시지를 소비하는 **Consumer**가 있고 요청을 받아 메시지를 저장하거나 꺼내주는 **Broker**로 구성
- 토스증권 - 주식거래를 위한 한국, 미국 주식시장의 체결가, 호가, 기타 각종 거래소 정보 실시간 제공
- 마이크로 서비스 아키텍처 구성으로 되어 있어 서비스 간 통신이나 서버의 비동기 처리를 주로 Kafka를 활용
- 외부 기관으로부터 메시지 수신 시 Kafka 활용
- 빅데이터 플랫폼 역할 - 서버와 클라이언트, 네트워크나 보안 장비에서 발생하는 모든 로그 Kafka로 입수
- 서비스 데이터베이스도 분석에 활용하기 위해 CDC라는 데이터베이스 변경사항 로그를 실시간으로 Kafka로 전송

![kafka 구조2](./img/image-1.png)

- 입수되는 메시지들은 Consumer가 용도에 맞는 저장소로 보내줌으로써 빅데이터 분석 및 서비스를 개발
- Kafka 아키텍처에서는 실시간으로 발생하는 로그를 필요에 맞게 변환하기 위한 스트리밍 프로세싱 플랫폼 필요 → 쿼리만으로 실시간 프로세싱이 가능한 ksqlDB 적극적 활용

## Kafka 이중화 목적

### 발생할 수 있는 장애 상황

#### Kafka Cluster 내의 일부 노드 장애

* 디스크, 메모리와 같은 하드웨어 장애부터 운영체제 설정 문제, Kafka 버그 등 발생 가능
* but, Kafka가 분산 시스템이기 때문에 클러스터 내 일부 노드 장애가 발생해도 가용성을 해치지 않고 서비스를 유지할 수 있도록 디자인
* 장애 징후를 감지하는 모니터링이나 장애 대응 프로세싱 정립으로 극복 가능

#### IDC 전면 장애

* IDC 이중화가 되어 있지 않다면 더 이상 서비스를 지속할 수 없어 치명적인 장애 상황
* IDC 이중화로 극복 가능
* 지속적인 서비스 제공 목표 달성을 위해 이중화 구성

### IDC 이중화가 되어 있지 않다면?

![IDC 구조](./img/image-2.png)

- 클라이언트가 한 곳의 IDC와 통신하며 주식 매매중
- IDC 장애가 해결이 되고 서버를 다시 살릴 때까지 토스 증권 서비스 사용 불가
- 증권사들은 이런 장애에 대응하도록 메인 IDC와 떨어져 다른 IDC에 **Disaster Recovery(DR)** 시스템 구축해야 함 → Active-Standby로 구성
    - Standby는 장애 상황 시에 Active가 될 준비를 하고 있다는 것
    - 장애 상황이 잦지 않기 때문에 평시에 잘 관리하고 있던 것이 아니면 막상 장애 상황 발생 시 제대로 동작하지 않는 경우도 발생
    - 시스템이 최신 버전을 유지하고 있지 않아 장애가 해결이 안 되는 경우도 발생
    - 따라서, 토스증권은 Active-Standby가 아닌 **Active-Active로 이중화를 구성**해 평시에도 두 개의 IDC 모두 Active로 사용하는 상태 진행
- IDC가 통째로 장애 나는 상황은 오직 이중화를 구성해서 막아낼 수 있음
- 따라서, 앞서 이야기 한 두 가지 장애 상황을 모두 이겨내기 위해 Kafka 이중화 구성이 필요하다.

## 토스증권의 Kafka 이중화 방법

### Kafka 이중화 단점

#### Kafka는 Stateful한 시스템이라 이중화 구성이 어렵다

![Alt text](./img/image-3.png)

- Kafka와 같은 Sateful한 시스템은 이중화 구성과 운영이 어렵다.
    - 저장 중인 메시지 자체가 STATE이기도 하고, 클러스터의 구성원이 누구인지, 리더가 누구인지도 STATE, Replica는 어디에 저장되어야 하는지, 나아가서 Consumer group의 소비 기록인 Offset도 모두 STATE
    - 서로 다른 IDC 두 개에 Kafka 클러스터를 구축하게 된다면 **어떻게 STATE 일관성을 유지할지** 고민해보고 구성해야 한다.

### 토스증권의 Kafka 이중화 방법

![Alt text](./img/image-4.png)

- 유저 트래픽이 IDC 두 곳으로 50%씩 들어가고 있음
    - IDC 두 곳을 Active-Active로 운영되고 있기 때문에
    - 각 IDC에 절반씩 들어온 메시지는 전체 메시지를 가질 수 있도록 Kafka Connect를 이용해 상대 쪽 IDC로 실시간 미러링
    - Offset Sync 데몬은 Consumer Group Offset을 실시간으로 양쪽간 IDC간 Sync를 맞춰줌
- Consumer는 한 개 인데, 양쪽 클러스터 각각 100%의 메시지를 갖고 있기 때문이다.
    - 메시지 중복 소비 방지

#### Kafka Connect

- 위와 같은 상황에서 Kafka에서 메시지를 소비하는 소비자는 메시지 전체가 아닌 절반만 가지게 됨
- Kafka Connect라는 메시지 미러링 도구가 반대쪽 IDC의 메시지를 가져오고 또 내 IDC의 메시지를 반대쪽으로 보내줌
- Consumer는 절반이 아닌 전체 메시지를 갖게 됨
- 이렇게 양방향 미러링을 해줘야 하는 잡이 라이브 중인 토픽 개수 만큼 필요
    - 이런 부분이 이중화 구성 후 운영 부담으로 찾아옴

#### Offset Sync

![Alt text](./img/image-5.png)

- Kafka에서 Offset은 Consumer Group이 어디까지 메시지를 소비했는지 번호로 나타낸 것
    - 이 번호를 알아야 유실, 중복 없이 메시지 지속 소비 가능
- Consumer는 Offset을 Kafka Broker에 저장하고 있기 때문에 이 Offset을 양쪽 모두가 가지고 있어야 함
- Consumer가 한쪽 클러스터에서 메시지를 소비하다 다른 IDC로 옮겨야 하는 경우가 발생하는데 보통 IDC 장애가 발생하거나 아니면 IDC에 잠깐 작업이 있어서 이사 가야 하는 경우
    - 이때 정상적으로 작업을 이어 하기 위해 Offset을 저장해야 함
- 메시지 미러링과 크게 다르지 않지만, Offset은 클러스터가 다르면 번호 체계가 달라지므로 중간에 상대 쪽 IDC에 맞는 번호로 변경해서 저장해야 하는 차이점
- **Offset Sync 데몬은 모든 Consumer Group들의 Offset을 상대 쪽 IDC와 Sync를 맞춰주는 역할**

#### 모니터링 부담 줄이기

1. 클러스터에서 발생하는 모든 매트릭 정보를 Prometheus로 수집
2. Thanos Ruler를 이용해 정의한 조건이 충족되면 알림
3. 클러스터의 모든 로그는 ElasticSearch로 실시간으로 수집하고 ElastAlert를 이용해 에러 로그 발생 시 알림을 주도록 구성

## IDC 장애 발생 시 우리의 대응

![Alt text](./img/image-6.png)

- 평시에는 IDC1, IDC2로 유저 트래픽이 절반씩 들어가고 있다.
- 서비스 서버는 각자 본인이 속한 IDC의 Kafka로 메시지 전송
- 동시에 IDC간 메시지 미러링과 Offset sync 작동
- Consumer는 그림과 같이 IDC1에서만 평화롭게 서비스 유지

#### IDC1에서 장애가 발생하면?

- 유저 트래픽을 모두 IDC2로 보냄
- IDC2 Kafka 클러스터가 모든 메시지를 받게 되는데, Kafka Broker 입장에서 메시지 일관성 측면을 보면 장애 발생 이전 IDC1에 들어오던 메시지는 실시간으로 IDC2로 미러링 중이었기 때문에 모든 메시지는 IDC2가 가지고 있을 수 있음
- 모든 메시지를 IDC2 Broker가 가지고 있기 때문에 메시지 일관성이 유지되고 있음
- Consumer만 IDC2로 바꾸어주기
    - Offset Sync 데몬이 실시간으로 IDC1에서 메시지를 어디까지 소비했었는지 IDC2에 Sync를 해주고 있었기 때문에 IDC1에서 IDC2로 주소만 바꿔서 새로 붙으면 이전에 소비하던 구간부터 유실 없이 재개 가능